{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e51e5e7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254587e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree as ET\n",
    "import resource\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = []\n",
    "results = []\n",
    "to_process = False\n",
    "root = \"{http://www.mediawiki.org/xml/export-0.10/}\"\n",
    "\n",
    "\n",
    "for event, elem in tqdm(ET.iterparse(\"commonswiki-20221001-pages-articles-multistream.xml\", events=(\"start\", \"end\"))):\n",
    "    if event == 'end':\n",
    "        if elem.tag in (root+\"ns\",root+\"text\",root+\"sha1\"):\n",
    "            if elem.tag == root+\"ns\":\n",
    "                if elem.text == \"102\":\n",
    "                    print(elem.text)\n",
    "                    to_process = True\n",
    "\n",
    "            if to_process == True:\n",
    "                if elem.tag == root+\"text\":\n",
    "                    text = elem.text\n",
    "                if elem.tag == root+\"comment\":\n",
    "                    comment = elem.text\n",
    "                    results.append({\"text\":text,\"comment\":comment})\n",
    "                    to_process=False\n",
    "        elem.clear()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40feedce",
   "metadata": {},
   "source": [
    "# Get transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57fda5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pages with NS = 102 (TimedText)\n",
    "import mwxml\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_dataset(xml_file ,output_file_name):\n",
    "    dump = mwxml.Dump.from_file(open(xml_file))\n",
    "    print(dump.site_info.name, dump.site_info.dbname)\n",
    "\n",
    "    pages = []\n",
    "    counter = 0\n",
    "    for page in tqdm(dump):\n",
    "        if page.namespace == 102:\n",
    "            counter+=1\n",
    "            for revision in page:\n",
    "                revision = revision\n",
    "            pages.append(revision)        \n",
    "            print(counter)\n",
    "\n",
    "    wikimedia = [i.to_json() for i in pages]\n",
    "\n",
    "    import json\n",
    "    with open(output_file_name , 'w') as file:\n",
    "        json.dump(wikimedia, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d2fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"wikimedia.json\" , 'r') as file:\n",
    "        previous_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f85890",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############# ESTE ES EL BUENO ###############\n",
    "\n",
    "from pyWikiCommons import pyWikiCommons\n",
    "import requests\n",
    "import os\n",
    "from google.cloud import storage\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Esto solo sirve para .webm\n",
    "def change_format(file_name):\n",
    "    import subprocess\n",
    "    changed_filename = os.rename(file_name, \"temp.webm\")\n",
    "    subprocess.run(f'ffmpeg -i \"temp.webm\" {file_name}.mp3',shell=True)\n",
    "    \n",
    "def download_file(url,file_name):\n",
    "    headers = {'User-Agent': 'CoolBot/0.0 (https://example.org/coolbot/; coolbot@example.org)'}\n",
    "    with requests.get(url, stream=True, headers=headers) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(file_name, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                f.write(chunk)\n",
    "    return file_name\n",
    "\n",
    "def split_with_last_dot(string):\n",
    "    for character in range(len(string)-1,0,-1):\n",
    "        if string[character]==\".\":\n",
    "            left = string[:character]\n",
    "            right = string[character+1:]\n",
    "            return [left,right]\n",
    "\n",
    "def upload_file_gcp(file_name, file_type):    \n",
    "    # Initiate names\n",
    "    project_id = 'the-peoples-speech' # Your Project ID\n",
    "    bucket_name = 'wikimedia_commons' # Name of bucket\n",
    "    bucket_file = f'{file_type}/{file_name}' # Location of the file on Bucket\n",
    "    local_file = f'{file_name}' # Location of downloaded file on your PC\n",
    "\n",
    "    # Set Credential\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"the-peoples-speech-ee8163e65ace.json\"\n",
    "    client = storage.Client(project_id)\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(bucket_file)\n",
    "    blob.upload_from_filename(local_file)\n",
    "    signed_url = blob.generate_signed_url(\n",
    "                    version=\"v4\",\n",
    "                    expiration=timedelta(seconds=60),\n",
    "                    method=\"GET\")\n",
    "\n",
    "\n",
    "    \n",
    "counter = 0\n",
    "database = {}\n",
    "for i in tqdm(range(13746,len(previous_json))):\n",
    "    link = previous_json[i][\"page\"][\"title\"]\n",
    "    dots = 0\n",
    "    try:\n",
    "        if len(link.split(\".\"))>2:\n",
    "            left,_ = split_with_last_dot(link)\n",
    "            true_link, _ = split_with_last_dot(left)\n",
    "\n",
    "\n",
    "            with open(link+\".txt\", 'w') as f:\n",
    "                f.write(previous_json[i][\"text\"])\n",
    "            upload_file_gcp(link+\".txt\", \"transcription\")\n",
    "            os.remove(link+\".txt\")\n",
    "\n",
    "            if true_link in database.keys():\n",
    "                database[true_link].append(link)\n",
    "            else:\n",
    "                database[true_link] = [link]\n",
    "                try:\n",
    "                    url = pyWikiCommons.get_commons_url(\"File:\" + true_link)\n",
    "                    file_name = download_file(url, true_link)\n",
    "                    upload_file_gcp(true_link, \"raw_videos\")\n",
    "                    os.remove(true_link)\n",
    "                    f = open(\"uploaded.txt\", \"a\")\n",
    "                    f.write(f\"{i},{true_link}\\n\")\n",
    "                    f.close()\n",
    "                except:\n",
    "                    f = open(\"error.txt\", \"a\")\n",
    "                    f.write(f\"{i},{true_link}\\n\")\n",
    "                    f.close()\n",
    "        else:\n",
    "            print(i)\n",
    "    except:\n",
    "        print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa1bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#link = previous_json[2345][\"page\"][\"title\"]\n",
    "#link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd5691c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_with_last_dot(string):\n",
    "    for character in range(len(string)-1,0,-1):\n",
    "        if string[character]==\".\":\n",
    "            left = string[:character]\n",
    "            right = string[character+1:]\n",
    "            return [left,right]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf1d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "path = 'The Impact of Wikipedia Dumisani Ndubane.webm'\n",
    "\n",
    "subprocess.run(f'ffmpeg -i {path} perro.mp3',shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584967b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcloud import storage\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import os\n",
    "\n",
    "credentials_dict = {\n",
    "    'type': 'service_account',\n",
    "    'client_id': os.environ['BACKUP_CLIENT_ID'],\n",
    "    'client_email': os.environ['BACKUP_CLIENT_EMAIL'],\n",
    "    'private_key_id': os.environ['BACKUP_PRIVATE_KEY_ID'],\n",
    "    'private_key': os.environ['BACKUP_PRIVATE_KEY'],\n",
    "}\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_dict(\n",
    "    credentials_dict\n",
    ")\n",
    "client = storage.Client(credentials=credentials, project='myproject')\n",
    "bucket = client.get_bucket('mybucket')\n",
    "blob = bucket.blob('myfile')\n",
    "blob.upload_from_filename('myfile')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51924ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382fd3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(60,120):\n",
    "    print(previous_json[i][\"page\"][\"title\"]) \n",
    "#'Edit Button.ogv.sl.srt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c1d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Wikipedia User Name MEDIUM.ogv.br.srt\"[::-1].split('.', 2)[-1][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf92409",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Wikipedia User Name MEDIUM.ogv.br.srt\"[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad168173",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyWikiCommons.get_commons_url(\"File:\" + true_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e8f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(database.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0473e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "database.has_key(\"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83545cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "x = requests.get('https://commons.wikimedia.org/wiki/File:Edit_Button.ogv')\n",
    "print(x.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb8ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "with open(\"test\", \"rb\") as fp:\n",
    "    b = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7653002",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb849a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458ee748",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://commons.wikimedia.org/wiki/TimedText:Elephants Dream.ogg.sv.srt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "links = []\n",
    "for transcription in b:\n",
    "    comment = transcription[\"comment\"]\n",
    "    if isinstance(comment, str):\n",
    "        splitted_comment = comment.split(\"TimedText:\")\n",
    "        if len(splitted_comment)>1:\n",
    "            link = []\n",
    "            for index in range(1,len(splitted_comment)):\n",
    "\n",
    "                limit = splitted_comment[index].find(\"]\")\n",
    "                print(\"links\")\n",
    "                print(splitted_comment[index][:limit])\n",
    "                link.append(splitted_comment[index][:limit])\n",
    "            links.append(link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4debe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pyWikiCommons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1acbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyWikiCommons import pyWikiCommons\n",
    "\n",
    "pyWikiCommons.get_commons_url(\"File:Elephants Dream.ogg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f10b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def download_file(url):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    # NOTE the stream=True parameter below\n",
    "    headers = {'User-Agent': 'CoolBot/0.0 (https://example.org/coolbot/; coolbot@example.org)'}\n",
    "    with requests.get(url, stream=True, headers=headers) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                # If you have chunk encoded response uncomment if\n",
    "                # and set chunk_size parameter to None.\n",
    "                #if chunk: \n",
    "                f.write(chunk)\n",
    "    return local_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9971f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://upload.wikimedia.org/wikipedia/commons/d/d5/Elephants_Dream.ogv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file(\"https://commons.wikimedia.org/wiki/TimedText:Elephants Dream.ogg.sv.srt&action=raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f6d3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "download_file(\"https://commons.wikimedia.org/w/index.php?title=TimedText:Elephants_Dream.ogv.en.srt&action=raw\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46421e8",
   "metadata": {},
   "source": [
    "# Files Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"database.json\" , 'r') as file:\n",
    "        database = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9062137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"error.txt\", 'r') as fp:\n",
    "    x = len(fp.readlines())\n",
    "    print('Total error Videos:', x)\n",
    "\n",
    "with open(r\"uploaded.txt\", 'r') as fp:\n",
    "    x = len(fp.readlines())\n",
    "    print('Total good Videos:', x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d1691",
   "metadata": {},
   "source": [
    "# Change Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89070ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_format(file_name):\n",
    "    import subprocess\n",
    "    changed_filename = os.rename(file_name, \"temp.webm\")\n",
    "    subprocess.run(f'ffmpeg -i \"temp.webm\" {file_name}.mp3',shell=True)\n",
    "\n",
    "change_format(\"video_1.webm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540ccd4d",
   "metadata": {},
   "source": [
    "# Upload file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import storage\n",
    "from datetime import timedelta\n",
    "\n",
    "# Initiate names\n",
    "project_id = 'the-peoples-speech' # Your Project ID\n",
    "bucket_name = 'wikimedia_commons' # Name of bucket\n",
    "bucket_file = 'test/error.txt' # Location of the file on Bucket\n",
    "local_file = 'error.txt' # Location of downloaded file on your PC\n",
    "\n",
    "# Set Credential\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"the-peoples-speech-ee8163e65ace.json\"\n",
    "client = storage.Client(project_id)\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "blob = bucket.blob(bucket_file)\n",
    "blob.upload_from_filename(local_file)\n",
    "signed_url = blob.generate_signed_url(\n",
    "                version=\"v4\",\n",
    "                expiration=timedelta(seconds=60),\n",
    "                method=\"GET\")\n",
    "# Print Signed URL\n",
    "print(signed_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d2ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\n",
    "        f\"File {source_file_name} uploaded to {destination_blob_name}.\"\n",
    "    )\n",
    "\n",
    "upload_blob(\"ensayo_1\", \"error.txt\", \"error.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dab3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_database.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1ffbd2",
   "metadata": {},
   "source": [
    "# Calculate video time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee5582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"wikimedia.json\" , 'r') as file:\n",
    "        previous_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "hour = 0\n",
    "minutes = 0\n",
    "secounds = 0\n",
    "no_text = []\n",
    "\n",
    "for register in range(len(previous_json)):\n",
    "    \n",
    "    try:\n",
    "        time = re.findall(\"(?:([01]?\\d|2[0-3]):([0-5]?\\d):)?([0-5]?\\d)\", previous_json[register][\"text\"])\n",
    "        for i in reversed(hours):\n",
    "            if i[0]!=\"\" and i[1]!=\"\" and i[2]!=\"\":\n",
    "                hour += int(i[0])\n",
    "                minutes += int(i[1])\n",
    "                secounds += int(i[2])\n",
    "                break\n",
    "    except:\n",
    "        no_text.append(register)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_minutes = minutes + secounds//60\n",
    "reformated_secounds = secounds%60\n",
    "reformated_hour = hour + temp_minutes//60\n",
    "reformated_minuts = minutes % 60\n",
    "print(f\"{reformated_hour}:{reformated_minuts}:{reformated_secounds}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763b841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "lista = []\n",
    "client = storage.Client()\n",
    "for blob in client.list_blobs('wikimedia_commons', prefix='raw_videos'):\n",
    "    lista.append(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7feed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(lista[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e43951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lista[500].download_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43dcbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "languaje count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364dfc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_with_last_dot(string):\n",
    "    for character in range(len(string)-1,0,-1):\n",
    "        if string[character]==\".\":\n",
    "            left = string[:character]\n",
    "            right = string[character+1:]\n",
    "            return [left,right]\n",
    "\n",
    "language_count = {}\n",
    "for key in database.keys():\n",
    "    for video in database[key]:\n",
    "        left,_ = split_with_last_dot(video)\n",
    "        _,language  = split_with_last_dot(left)\n",
    "        if language not in language_count.keys():\n",
    "            language_count[language]=1\n",
    "        else:\n",
    "            language_count[language]+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9ea3ef",
   "metadata": {},
   "source": [
    "# Change format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444537d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import subprocess\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "\n",
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    downloads_folder = pathlib.Path.cwd()\n",
    "    file = downloads_folder.joinpath(destination_file_name)\n",
    "\n",
    "    blob.download_to_filename(file)\n",
    "\n",
    "def change_format(file_name):\n",
    "    subprocess.run(f'ffmpeg -vn -sn -i {file_name} temp.flac',shell=True)\n",
    "    \n",
    "def split_with_last_dot(string):\n",
    "    for character in range(len(string)-1,0,-1):\n",
    "        if string[character]==\".\":\n",
    "            left = string[:character]\n",
    "            right = string[character+1:]\n",
    "            return [left,right]\n",
    "        \n",
    "def upload_file_gcp(file_name, file_type):    \n",
    "    # Initiate names\n",
    "    project_id = 'the-peoples-speech' # Your Project ID\n",
    "    bucket_name = 'wikimedia_commons' # Name of bucket\n",
    "    bucket_file = f'{file_type}/{file_name}' # Location of the file on Bucket\n",
    "    local_file = f'temp.flac' # Location of downloaded file on your PC\n",
    "\n",
    "    # Set Credential\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"the-peoples-speech-ee8163e65ace.json\"\n",
    "    client = storage.Client(project_id)\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(bucket_file)\n",
    "    blob.upload_from_filename(local_file)\n",
    "    signed_url = blob.generate_signed_url(\n",
    "                    version=\"v4\",\n",
    "                    expiration=timedelta(seconds=200),\n",
    "                    method=\"GET\")\n",
    "\n",
    "with open(r\"fail_reformat.txt\", 'r') as fp:\n",
    "    x = fp.readlines()\n",
    "    \n",
    "actual_video = 70  \n",
    "for missing_file in tqdm(x):\n",
    "    missing_file_converted = f\"raw_videos/{missing_file}\"[:-6]\n",
    "    for i in range(70,len(files_list)):\n",
    "        if files_list[i].name==missing_file_converted:\n",
    "            file = files_list[i]\n",
    "            file_name ,ext = split_with_last_dot(file.name)\n",
    "            actual_video = i\n",
    "            try:\n",
    "                download_blob(\"wikimedia_commons\", file.name, f\"temp.{ext}\")\n",
    "                if ext != \"flac\":\n",
    "                    change_format(f\"'temp.{ext}'\")\n",
    "                upload_file_gcp(f\"{file_name[11:]}.flac\", \"reformat\")\n",
    "                if ext != \"flac\":\n",
    "                    os.remove(f'temp.{ext}')\n",
    "                os.remove(f'temp.flac')\n",
    "                f = open(\"new_reformat.txt\", \"a\")\n",
    "                f.write(f\"{file_name[11:]}.flac\\n\")\n",
    "                f.close()\n",
    "                print(\"success\")\n",
    "            except:\n",
    "                f = open(\"new_fail_reformat.txt\", \"a\")\n",
    "                f.write(f\"{file.name[11:]}.flac\\n\")\n",
    "                f.close()\n",
    "                print(file.name[11:])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a0505",
   "metadata": {},
   "source": [
    "Apply ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bace4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# ESTE ES PARA TRANSCRIPCIONES ###############\n",
    "\n",
    "import ftfy\n",
    "from pyWikiCommons import pyWikiCommons\n",
    "import requests\n",
    "import os\n",
    "from google.cloud import storage\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Esto solo sirve para .webm\n",
    "def change_format(file_name):\n",
    "    import subprocess\n",
    "    changed_filename = os.rename(file_name, \"temp.webm\")\n",
    "    subprocess.run(f'ffmpeg -i \"temp.webm\" {file_name}.mp3',shell=True)\n",
    "    \n",
    "def download_file(url,file_name):\n",
    "    headers = {'User-Agent': 'CoolBot/0.0 (https://example.org/coolbot/; coolbot@example.org)'}\n",
    "    with requests.get(url, stream=True, headers=headers) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(file_name, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                f.write(chunk)\n",
    "    return file_name\n",
    "\n",
    "def split_with_last_dot(string):\n",
    "    for character in range(len(string)-1,0,-1):\n",
    "        if string[character]==\".\":\n",
    "            left = string[:character]\n",
    "            right = string[character+1:]\n",
    "            return [left,right]\n",
    "\n",
    "def upload_file_gcp(file_name, file_type):    \n",
    "    # Initiate names\n",
    "    project_id = 'the-peoples-speech' # Your Project ID\n",
    "    bucket_name = 'wikimedia_commons' # Name of bucket\n",
    "    bucket_file = f'{file_type}/{file_name}' # Location of the file on Bucket\n",
    "    local_file = f'{file_name}' # Location of downloaded file on your PC\n",
    "\n",
    "    # Set Credential\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"the-peoples-speech-ee8163e65ace.json\"\n",
    "    client = storage.Client(project_id)\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(bucket_file)\n",
    "    blob.upload_from_filename(local_file)\n",
    "    signed_url = blob.generate_signed_url(\n",
    "                    version=\"v4\",\n",
    "                    expiration=timedelta(seconds=60),\n",
    "                    method=\"GET\")\n",
    "\n",
    "\n",
    "    \n",
    "counter = 0\n",
    "database = {}\n",
    "for i in tqdm(range(len(previous_json))):\n",
    "    link = previous_json[i][\"page\"][\"title\"]\n",
    "    dots = 0\n",
    "    try:\n",
    "        if len(link.split(\".\"))>2:\n",
    "            left,_ = split_with_last_dot(link)\n",
    "            true_link, _ = split_with_last_dot(left)\n",
    "\n",
    "\n",
    "            with open(link, 'w') as f:\n",
    "                f.write(ftfy.fix_text(previous_json[i][\"text\"]))\n",
    "            upload_file_gcp(link, \"transcription\")\n",
    "            os.remove(link)            \n",
    "\n",
    "            if true_link in database.keys():\n",
    "                database[true_link].append(link)\n",
    "            else:\n",
    "                database[true_link] = [link]\n",
    "                try:\n",
    "                    f = open(\"uploaded.txt\", \"a\")\n",
    "                    f.write(f\"{i},{true_link}\\n\")\n",
    "                    f.close()\n",
    "                except:\n",
    "                    f = open(\"error.txt\", \"a\")\n",
    "                    f.write(f\"{i},{true_link}\\n\")\n",
    "                    f.close()\n",
    "        else:\n",
    "            print(i)\n",
    "    except:\n",
    "        print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:factored]",
   "language": "python",
   "name": "conda-env-factored-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
